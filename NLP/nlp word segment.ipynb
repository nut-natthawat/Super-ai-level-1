{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91251,"databundleVersionId":10905660,"sourceType":"competition"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T21:36:32.430436Z","iopub.execute_input":"2025-01-25T21:36:32.430733Z","iopub.status.idle":"2025-01-25T21:36:35.835334Z","shell.execute_reply.started":"2025-01-25T21:36:32.430708Z","shell.execute_reply":"2025-01-25T21:36:35.834540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# ฟังก์ชันสำหรับอ่านไฟล์จากโฟลเดอร์ตามลำดับ\ndef read_data_from_folder(folder_path):\n    data = []\n    # เรียงลำดับชื่อไฟล์ตามลำดับตัวเลข\n    file_names = sorted(os.listdir(folder_path))\n    for file_name in file_names:\n        if file_name.endswith(\".txt\"):\n            file_path = os.path.join(folder_path, file_name)\n\n            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n                for line in file:\n                    line = line.strip()\n                    if line:  # ข้ามแถวว่าง\n                        parts = line.split(\"\\t\")\n                        if len(parts) == 4:  # ถ้ามี 4 คอลัมน์\n                            data.append(parts)\n                        elif len(parts) == 3:  # ถ้ามี 3 คอลัมน์ เติมค่า default สำหรับ `tag`\n                            parts.insert(2, \"O\")  # ใส่ค่า \"O\" ที่ตำแหน่ง index 2\n                            data.append(parts)\n                        else:\n                            print(f\"Invalid line in {file_name}: {line}\")\n    return data\n\n# ฟังก์ชันสำหรับรวบรวมและบันทึกข้อมูล\ndef process_and_save_data(input_folder, output_file):\n    data = read_data_from_folder(input_folder)\n    df = pd.DataFrame(data, columns=[\"word\", \"pos\", \"tag\", \"class\"])\n    df.to_csv(output_file, index=False, encoding=\"utf-8\")\n    print(f\"Saved processed data to {output_file}\")\n\n# โฟลเดอร์ข้อมูล (แก้ไขให้ตรงกับโครงสร้างใน Kaggle)\ntrain_folder = \"/kaggle/input/super-ai-ss-5-named-entity-recognition/train/train\"\ntest_folder = \"/kaggle/input/super-ai-ss-5-named-entity-recognition/test/test\"\neval_folder = \"/kaggle/input/super-ai-ss-5-named-entity-recognition/eval/eval\"\n\n# เซฟข้อมูลเป็นไฟล์ CSV\nprocess_and_save_data(train_folder, \"train_data.csv\")\nprocess_and_save_data(eval_folder, \"eval_data.csv\")\nprocess_and_save_data(test_folder, \"test_data.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:07:55.832832Z","iopub.execute_input":"2025-01-26T00:07:55.833154Z","iopub.status.idle":"2025-01-26T00:08:15.119126Z","shell.execute_reply.started":"2025-01-26T00:07:55.833129Z","shell.execute_reply":"2025-01-26T00:08:15.118031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%pip install simpletransformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:08:18.810212Z","iopub.execute_input":"2025-01-26T00:08:18.810463Z","iopub.status.idle":"2025-01-26T00:08:22.405925Z","shell.execute_reply.started":"2025-01-26T00:08:18.810435Z","shell.execute_reply":"2025-01-26T00:08:22.404797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# โหลดข้อมูล\ntrain_data = pd.read_csv('train_data.csv')\neval_data = pd.read_csv('eval_data.csv')\ntest_data = pd.read_csv('test_data.csv')\n\n# ตรวจสอบตัวอย่างข้อมูล\nprint(train_data.head())\nprint(eval_data.head())\nprint(test_data.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:08:22.407853Z","iopub.execute_input":"2025-01-26T00:08:22.408148Z","iopub.status.idle":"2025-01-26T00:08:24.050384Z","shell.execute_reply.started":"2025-01-26T00:08:22.408123Z","shell.execute_reply":"2025-01-26T00:08:24.049487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tag_list = [\n    ('O', 0),\n    ('B_ORG', 1),  ('B_PER', 2),  ('B_LOC', 3),  ('B_MEA', 4),\n    ('I_DTM', 5),  ('I_ORG', 6),  ('E_ORG', 7),  ('I_PER', 8),\n    ('B_TTL', 9),  ('E_PER', 10), ('B_DES', 11), ('E_LOC', 12),\n    ('B_DTM', 13), ('B_NUM', 14), ('I_MEA', 15), ('E_DTM', 16),\n    ('E_MEA', 17), ('I_LOC', 18), ('I_DES', 19), ('E_DES', 20),\n    ('I_NUM', 21), ('E_NUM', 22), ('B_TRM', 23), ('B_BRN', 24),\n    ('I_TRM', 25), ('E_TRM', 26), ('I_TTL', 27), ('I_BRN', 28),\n    ('E_BRN', 29), ('E_TTL', 30), ('B_NAME', 31)\n]\ntag_to_id = dict(tag_list)\nid_to_tag = {v: k for k, v in tag_to_id.items()}\n\ndef get_tag_id(tag):\n    # Map unknown tags to 0 (O)\n    return tag_to_id.get(tag, 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:08:24.051376Z","iopub.execute_input":"2025-01-26T00:08:24.051733Z","iopub.status.idle":"2025-01-26T00:08:24.057953Z","shell.execute_reply.started":"2025-01-26T00:08:24.051700Z","shell.execute_reply":"2025-01-26T00:08:24.057239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef group_sentences_with_id(data, is_test=False):\n    sentences = []\n    sentence = []\n    sentence_id = 0\n\n    for idx, row in data.iterrows():\n        word, tag, cls = row['word'], row['tag'], row['class']\n\n        if idx >= 1300000 and not is_test:  # Remove this line\n            break\n        \n        if is_test:\n            if cls == 'B_CLS':\n                if sentence:  \n                    sentences.append({'sentence_id': sentence_id, 'words': sentence})\n                    sentence_id += 1\n                sentence = [(word, tag)]\n            elif cls == 'I_CLS':\n                sentence.append((word, tag))\n\n            elif cls == 'E_CLS':\n                sentence.append((word, tag))\n                sentences.append({'sentence_id': sentence_id, 'words': sentence})\n                sentence = []\n                sentence_id += 1\n        else:\n            if tag not in tag_to_id:\n                continue\n\n            if cls == 'B_CLS':\n                if sentence:\n                    sentences.append({'sentence_id': sentence_id, 'words': sentence})\n                    sentence_id += 1\n                sentence = [(word, tag)]\n            elif cls == 'I_CLS':\n                sentence.append((word, tag))\n            elif cls == 'E_CLS':\n                sentence.append((word, tag))\n                sentences.append({'sentence_id': sentence_id, 'words': sentence})\n                sentence = []\n                sentence_id += 1\n\n    if sentence:\n        sentences.append({'sentence_id': sentence_id, 'words': sentence})\n\n    return sentences\n\ndef create_dataframe(sentences):\n    data = []\n\n    for sentence in sentences:\n        sentence_id = sentence['sentence_id']\n        tokens = [word for word, tag in sentence['words']]\n        ner_tags = [tag for word, tag in sentence['words']]\n\n        data.append({'id': sentence_id, 'tokens': tokens, 'ner_tags': ner_tags})\n\n    return pd.DataFrame(data)\n\ntrain_sentences = group_sentences_with_id(train_data)\neval_sentences = group_sentences_with_id(eval_data)\ntest_sentences = group_sentences_with_id(test_data, is_test=True)\n\ntrain_df = create_dataframe(train_sentences)\neval_df = create_dataframe(eval_sentences)\ntest_df = create_dataframe(test_sentences)\n\nprint(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:08:24.058822Z","iopub.execute_input":"2025-01-26T00:08:24.059118Z","iopub.status.idle":"2025-01-26T00:09:40.961495Z","shell.execute_reply.started":"2025-01-26T00:08:24.059097Z","shell.execute_reply":"2025-01-26T00:09:40.960556Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_data_to_df(df):\n  data_df = pd.DataFrame()\n  sentence_id = []\n  words = []\n  labels = []\n\n  for sentence in range(len(df)):\n    for token in range(len(df['tokens'][sentence])):\n      sentence_id.append(sentence)\n      words.append(df['tokens'][sentence][token])\n      labels.append(df['ner_tags'][sentence][token])\n  return pd.DataFrame(\n      {\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels}\n  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:09:40.962313Z","iopub.execute_input":"2025-01-26T00:09:40.962537Z","iopub.status.idle":"2025-01-26T00:09:40.967684Z","shell.execute_reply.started":"2025-01-26T00:09:40.962517Z","shell.execute_reply":"2025-01-26T00:09:40.966743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_data = convert_data_to_df(eval_df)\ntrain_data = convert_data_to_df(train_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:09:40.969430Z","iopub.execute_input":"2025-01-26T00:09:40.969637Z","iopub.status.idle":"2025-01-26T00:09:55.937508Z","shell.execute_reply.started":"2025-01-26T00:09:40.969619Z","shell.execute_reply":"2025-01-26T00:09:55.936728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from simpletransformers.ner import NERModel\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:09:55.938467Z","iopub.execute_input":"2025-01-26T00:09:55.938745Z","iopub.status.idle":"2025-01-26T00:09:55.941942Z","shell.execute_reply.started":"2025-01-26T00:09:55.938721Z","shell.execute_reply":"2025-01-26T00:09:55.941315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_args = {\n    'num_train_epochs': 2,\n    'learning_rate': 1e-4,\n    'max_seq_length': 128,\n    'train_batch_size': 32,\n    'eval_batch_size': 32,\n    'overwrite_output_dir': True,\n    'save_steps': -1,\n    'save_model_every_epoch': False\n}\nmodel = NERModel(\n    'bert',\n    'bert-base-multilingual-cased',\n    labels=list(tag_to_id.keys()),\n    args=model_args\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:09:55.942754Z","iopub.execute_input":"2025-01-26T00:09:55.942983Z","iopub.status.idle":"2025-01-26T00:09:56.505885Z","shell.execute_reply.started":"2025-01-26T00:09:55.942954Z","shell.execute_reply":"2025-01-26T00:09:56.504861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:09:56.506945Z","iopub.execute_input":"2025-01-26T00:09:56.507322Z","iopub.status.idle":"2025-01-26T00:09:56.519373Z","shell.execute_reply.started":"2025-01-26T00:09:56.507287Z","shell.execute_reply":"2025-01-26T00:09:56.518398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train_model(train_data, eval_data=eval_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:10:04.902036Z","iopub.execute_input":"2025-01-26T00:10:04.902367Z","iopub.status.idle":"2025-01-26T00:30:34.248196Z","shell.execute_reply.started":"2025-01-26T00:10:04.902341Z","shell.execute_reply":"2025-01-26T00:30:34.247111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:04:28.442158Z","iopub.execute_input":"2025-01-26T00:04:28.442503Z","iopub.status.idle":"2025-01-26T00:04:28.453881Z","shell.execute_reply.started":"2025-01-26T00:04:28.442477Z","shell.execute_reply":"2025-01-26T00:04:28.452973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def split_into_sentences(tokens, tokens_per_sentence=24):\n    sentences = []\n    for i in range(0, len(tokens), tokens_per_sentence):\n        sentence = tokens[i:i + tokens_per_sentence]\n        sentences.append(sentence)\n    return sentences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:30:38.319892Z","iopub.execute_input":"2025-01-26T00:30:38.320230Z","iopub.status.idle":"2025-01-26T00:30:38.324865Z","shell.execute_reply.started":"2025-01-26T00:30:38.320202Z","shell.execute_reply":"2025-01-26T00:30:38.324120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cat_string(df):\n  text = []\n  for i in df['word']:\n    text.append(str(i))\n  return text\n\ntest_txt_list = cat_string(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:30:39.871855Z","iopub.execute_input":"2025-01-26T00:30:39.872283Z","iopub.status.idle":"2025-01-26T00:30:39.918493Z","shell.execute_reply.started":"2025-01-26T00:30:39.872240Z","shell.execute_reply":"2025-01-26T00:30:39.917624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df_prepared = split_into_sentences(test_txt_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:30:41.188726Z","iopub.execute_input":"2025-01-26T00:30:41.189038Z","iopub.status.idle":"2025-01-26T00:30:41.201972Z","shell.execute_reply.started":"2025-01-26T00:30:41.188985Z","shell.execute_reply":"2025-01-26T00:30:41.201171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def format_test_data(test_data):\n    formatted_data = [\" \".join(sentence) for sentence in test_data]\n    return formatted_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:30:42.585565Z","iopub.execute_input":"2025-01-26T00:30:42.585889Z","iopub.status.idle":"2025-01-26T00:30:42.589826Z","shell.execute_reply.started":"2025-01-26T00:30:42.585859Z","shell.execute_reply":"2025-01-26T00:30:42.588905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions, raw_outputs = model.predict(test_df_prepared,False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:30:43.963762Z","iopub.execute_input":"2025-01-26T00:30:43.964103Z","iopub.status.idle":"2025-01-26T00:31:29.349421Z","shell.execute_reply.started":"2025-01-26T00:30:43.964072Z","shell.execute_reply":"2025-01-26T00:31:29.348609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions[0][0:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:31:31.636076Z","iopub.execute_input":"2025-01-26T00:31:31.636401Z","iopub.status.idle":"2025-01-26T00:31:31.642096Z","shell.execute_reply.started":"2025-01-26T00:31:31.636375Z","shell.execute_reply":"2025-01-26T00:31:31.641249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_test_df = []\nfor i in range(len(predictions)):\n  for j in range(len(predictions[i])):\n    data = predictions[i][j]\n    value = data.values()\n    final_test_df += value","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:31:34.765863Z","iopub.execute_input":"2025-01-26T00:31:34.766222Z","iopub.status.idle":"2025-01-26T00:31:34.846373Z","shell.execute_reply.started":"2025-01-26T00:31:34.766190Z","shell.execute_reply":"2025-01-26T00:31:34.845488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ner_list = pd.read_csv(\"/kaggle/input/super-ai-ss-5-named-entity-recognition/tag_list.csv\")\nner_list.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:31:35.994410Z","iopub.execute_input":"2025-01-26T00:31:35.994742Z","iopub.status.idle":"2025-01-26T00:31:36.012624Z","shell.execute_reply.started":"2025-01-26T00:31:35.994712Z","shell.execute_reply":"2025-01-26T00:31:36.011966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Final_NER = []\ncount = 0\nfor tags in final_test_df:\n  count = 0\n  for i in ner_list[\"tag\"]:\n    if tags == i:\n      Final_NER.append(str(ner_list[\"class\"][count]))\n    count += 1\nprint(Final_NER[0:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:31:37.865616Z","iopub.execute_input":"2025-01-26T00:31:37.865937Z","iopub.status.idle":"2025-01-26T00:31:40.897293Z","shell.execute_reply.started":"2025-01-26T00:31:37.865908Z","shell.execute_reply":"2025-01-26T00:31:40.896532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_result = pd.DataFrame(Final_NER)\nfinal_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:31:44.350362Z","iopub.execute_input":"2025-01-26T00:31:44.350653Z","iopub.status.idle":"2025-01-26T00:31:44.371756Z","shell.execute_reply.started":"2025-01-26T00:31:44.350629Z","shell.execute_reply":"2025-01-26T00:31:44.370862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submisstion_df = pd.read_csv('/kaggle/input/super-ai-ss-5-named-entity-recognition/sample_submission.csv')\nsubmisstion_df['ne'] = final_result\nsubmisstion_df.head(15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:31:46.504323Z","iopub.execute_input":"2025-01-26T00:31:46.504622Z","iopub.status.idle":"2025-01-26T00:31:46.613647Z","shell.execute_reply.started":"2025-01-26T00:31:46.504598Z","shell.execute_reply":"2025-01-26T00:31:46.612920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submisstion_df[['id', 'ne']].to_csv('submissionfinal3.csv', index = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T00:31:53.492582Z","iopub.execute_input":"2025-01-26T00:31:53.492868Z","iopub.status.idle":"2025-01-26T00:31:53.633579Z","shell.execute_reply.started":"2025-01-26T00:31:53.492845Z","shell.execute_reply":"2025-01-26T00:31:53.632882Z"}},"outputs":[],"execution_count":null}]}