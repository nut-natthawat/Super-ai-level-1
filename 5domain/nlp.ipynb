{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":94866,"databundleVersionId":11278130,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:46:05.187538Z","iopub.execute_input":"2025-03-08T22:46:05.187864Z","iopub.status.idle":"2025-03-08T22:46:05.530995Z","shell.execute_reply.started":"2025-03-08T22:46:05.187824Z","shell.execute_reply":"2025-03-08T22:46:05.530035Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-word-segmentation/ws_test.txt\n/kaggle/input/nlp-word-segmentation/LST20 Brief Specification.pdf\n/kaggle/input/nlp-word-segmentation/ws_list.txt\n/kaggle/input/nlp-word-segmentation/LST20 Annotation Guideline.pdf\n/kaggle/input/nlp-word-segmentation/ws_sample_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install pythainlp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:47:05.691164Z","iopub.execute_input":"2025-03-08T22:47:05.691503Z","iopub.status.idle":"2025-03-08T22:47:11.397549Z","shell.execute_reply.started":"2025-03-08T22:47:05.691476Z","shell.execute_reply":"2025-03-08T22:47:11.396571Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting pythainlp\n  Downloading pythainlp-5.1.0-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->pythainlp) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->pythainlp) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->pythainlp) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->pythainlp) (2025.1.31)\nDownloading pythainlp-5.1.0-py3-none-any.whl (19.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pythainlp\nSuccessfully installed pythainlp-5.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"pip install attacut","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:47:27.979004Z","iopub.execute_input":"2025-03-08T22:47:27.979357Z","iopub.status.idle":"2025-03-08T22:47:36.724126Z","shell.execute_reply.started":"2025-03-08T22:47:27.979328Z","shell.execute_reply":"2025-03-08T22:47:36.723001Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting attacut\n  Downloading attacut-1.0.6-py3-none-any.whl.metadata (4.0 kB)\nCollecting docopt>=0.6.2 (from attacut)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting fire>=0.1.3 (from attacut)\n  Downloading fire-0.7.0.tar.gz (87 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting nptyping>=0.2.0 (from attacut)\n  Downloading nptyping-2.5.0-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from attacut) (1.26.4)\nRequirement already satisfied: pyyaml>=5.1.2 in /usr/local/lib/python3.10/dist-packages (from attacut) (6.0.2)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from attacut) (1.17.0)\nCollecting ssg>=0.0.4 (from attacut)\n  Downloading ssg-0.0.8-py3-none-any.whl.metadata (762 bytes)\nRequirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from attacut) (2.5.1+cu121)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.1.3->attacut) (2.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->attacut) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->attacut) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->attacut) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->attacut) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->attacut) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17.0->attacut) (2.4.1)\nCollecting python-crfsuite>=0.9.6 (from ssg>=0.0.4->attacut)\n  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from ssg>=0.0.4->attacut) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->attacut) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.2.0->attacut) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.2.0->attacut) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.0->attacut) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17.0->attacut) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.0->attacut) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17.0->attacut) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17.0->attacut) (2024.2.0)\nDownloading attacut-1.0.6-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nptyping-2.5.0-py3-none-any.whl (37 kB)\nDownloading ssg-0.0.8-py3-none-any.whl (473 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: docopt, fire\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=0084b07a5cdae08374fa680f7ea08e5d6e015bfce937cec5be405a2bd03c1a07\n  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=e3d7ec7b44f3a6ae795521773ad0252fe0c09ef29796daf0e763f1fc73859fdc\n  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\nSuccessfully built docopt fire\nInstalling collected packages: docopt, python-crfsuite, fire, ssg, nptyping, attacut\nSuccessfully installed attacut-1.0.6 docopt-0.6.2 fire-0.7.0 nptyping-2.5.0 python-crfsuite-0.9.11 ssg-0.0.8\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nfrom pythainlp.tokenize import word_tokenize\nfrom tqdm import tqdm\n\ndef add_word_tags(text):\n    words = word_tokenize(text, engine=\"attacut\")\n    tagged_tokens = []\n    for word in words:\n        if word.strip() == \"\":\n            continue\n        word_len = len(word)\n        for i in range(word_len):\n            if i == 0:\n                tagged_tokens.append('B_WORD') \n            elif i == word_len - 1:\n                tagged_tokens.append('E_WORD')  \n            else:\n                tagged_tokens.append('I_WORD')  \n    return tagged_tokens\n\ndef process_and_write_to_csv(input_file, output_file):\n    try:\n        with open(input_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n    except Exception as e:\n        print(f\"เกิดข้อผิดพลาดในการอ่านไฟล์: {e}\")\n        return None\n    \n    chars = list(text)\n    is_space = [c.isspace() for c in chars]\n    \n    non_space_chars = []\n    original_positions = []\n    \n    for i, (char, space) in enumerate(zip(chars, is_space)):\n        if not space:\n            non_space_chars.append(char)\n            original_positions.append(i + 1)\n            \n    non_space_text = ''.join(non_space_chars)\n    \n    chunks = []\n    positions_chunks = []\n    chunk_size = 10000\n    \n    for i in range(0, len(non_space_text), chunk_size):\n        end = min(i + chunk_size, len(non_space_text))\n        chunks.append(non_space_text[i:end])\n        positions_chunks.append(original_positions[i:end])\n    \n    all_tags = []\n    all_positions = []\n    \n    for chunk_idx, (chunk, positions) in enumerate(zip(chunks, positions_chunks)):\n        words = word_tokenize(chunk, engine=\"attacut\")\n        \n        char_idx = 0\n        for word in words:\n            if len(word) == 1:\n                all_tags.append(\"B_WORD\")\n                all_positions.append(positions[char_idx])\n                char_idx += 1\n            else:\n                all_tags.append(\"B_WORD\")\n                all_positions.append(positions[char_idx])\n                char_idx += 1\n                \n                for _ in range(len(word) - 2):\n                    all_tags.append(\"I_WORD\")\n                    all_positions.append(positions[char_idx])\n                    char_idx += 1\n                \n                all_tags.append(\"E_WORD\")\n                all_positions.append(positions[char_idx])\n                char_idx += 1\n    \n    if len(all_tags) != len(non_space_chars):\n        if len(all_tags) < len(non_space_chars):\n            missing = len(non_space_chars) - len(all_tags)\n            for i in range(len(all_tags), len(non_space_chars)):\n                all_tags.append(\"B_WORD\")\n                all_positions.append(original_positions[i])\n        else:\n            all_tags = all_tags[:len(non_space_chars)]\n            all_positions = all_positions[:len(non_space_chars)]\n    \n    submission_df = pd.DataFrame({\n        'Id': all_positions,\n        'Predicted': all_tags\n    })\n    \n    submission_df = submission_df.sort_values(by='Id').reset_index(drop=True)\n    \n    submission_df.to_csv(output_file, index=False)\n    \n    print(f\"บันทึกไฟล์ {output_file} สำเร็จ\")\n    print(f\"จำนวนแถว: {len(submission_df)}\")\n    \n    tag_counts = submission_df['Predicted'].value_counts()\n    for tag, count in tag_counts.items():\n        print(f\"{tag}: {count} ({count/len(submission_df)*100:.2f}%)\")\n    \n    return submission_df\n\ninput_file = '/kaggle/input/nlp-word-segmentation/ws_test.txt'\noutput_file = '/kaggle/working/submissionnn.csv'\n\nprocess_and_write_to_csv(input_file, output_file)\n\nprint('เสร็จ')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T22:48:02.628664Z","iopub.execute_input":"2025-03-08T22:48:02.628987Z","iopub.status.idle":"2025-03-08T22:48:03.586182Z","shell.execute_reply.started":"2025-03-08T22:48:02.628958Z","shell.execute_reply":"2025-03-08T22:48:03.585467Z"}},"outputs":[{"name":"stdout","text":"บันทึกไฟล์ /kaggle/working/submissionnn.csv สำเร็จ\nจำนวนแถว: 35182\nI_WORD: 19827 (56.36%)\nB_WORD: 7785 (22.13%)\nE_WORD: 7570 (21.52%)\nเสร็จ\n","output_type":"stream"}],"execution_count":8}]}